{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import plotly.plotly as py\n",
    "from plotly.graph_objs import *\n",
    "import plotly.tools as tls\n",
    "py.sign_in('glemaitre', 'se04g0bmi2')\n",
    "\n",
    "import mpld3\n",
    "\n",
    "import seaborn as sns; sns.set()\n",
    "sns.palplot(sns.color_palette(\"muted\"))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from scipy.stats import norm,rayleigh,rice\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy.stats.mstats import mode\n",
    "\n",
    "from skimage import exposure\n",
    "\n",
    "# Joblib library\n",
    "### Module to performed parallel processing\n",
    "from joblib import Parallel, delayed\n",
    "# Multiprocessing library\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Impor the mat containing the gray levels information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "\n",
    "matfiles = loadmat('../data/mat/all_voxels.mat');\n",
    "\n",
    "data = np.asmatrix(matfiles['data'])\n",
    "data = data.astype(float)\n",
    "label = np.ravel(matfiles['label'])\n",
    "patient_sizes = np.ravel(matfiles['patient_sizes'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load only the dce dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dce = np.asmatrix(data[:, 3:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a class Patient to facilitate data management.\n",
    "\n",
    "The data are the DCE and this sequence is composed of multiple series. Thus, there is a need to compute information for each serie composing the DCE:\n",
    "\n",
    "* the minimum intensity of the serie,\n",
    "* the maximum intensity of the serie,\n",
    "* the pdf of the serie,\n",
    "* the mean of the serie,\n",
    "* the std of the serie,\n",
    "* the parameters of a Gaussian fitting on the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Patient(object):\n",
    "    def __init__(self, data):\n",
    "        self.data = data.copy()\n",
    "        # Allocation of the minimum and maximum array for the series\n",
    "        self.max_int_serie = []\n",
    "        self.min_int_serie = []\n",
    "        # Allocate the pdf and the bin_edges\n",
    "        self.pdf_serie = []\n",
    "        self.bin_edges_serie = []\n",
    "        # Allocate the mean and std of the data\n",
    "        self.mean_data_serie = []\n",
    "        self.median_data_serie = []\n",
    "        self.std_data_serie = []\n",
    "        self.gaussian_params_serie = []\n",
    "        self.idx_mean = []\n",
    "        self.idx_median = []\n",
    "        self.mode_data_serie = []\n",
    "        for serie in range(data.shape[1]):\n",
    "            # Find the minimum and maximum for the given serie\n",
    "            self.max_int_serie.append(np.max(self.data[:, serie]))\n",
    "            self.min_int_serie.append(np.min(self.data[:, serie]))\n",
    "            # Compute the histogram\n",
    "            pdf, bin_edges = np.histogram(self.data[:, serie],\n",
    "                                                    bins = (self.max_int_serie[-1] - self.min_int_serie[-1]),\n",
    "                                                    density=True)\n",
    "            # Append the histogram\n",
    "            self.pdf_serie.append(pdf)\n",
    "            self.bin_edges_serie.append(bin_edges)\n",
    "        \n",
    "            self.mean_data_serie.append(np.mean(self.data[:, serie]))\n",
    "            self.std_data_serie.append(np.std(self.data[:, serie]))\n",
    "            self.median_data_serie.append(np.ravel(np.median(self.data[:, serie], axis=0)))\n",
    "            #tmp_mode, tmp_idx = mode(self.data[:, serie], axis=None)\n",
    "            #self.mode_data_serie.append(np.ravel(tmp_mode)[0])\n",
    "            \n",
    "            #print serie\n",
    "            #print self.mode_data_serie\n",
    "            \n",
    "            # Find the index of the mean and the median for this serie\n",
    "            ##### WRONG\n",
    "            def argmean(x):\n",
    "                x_mean = np.mean(np.ravel(x))\n",
    "                return (np.abs(x-x_mean)).argmin()\n",
    "            \n",
    "            def argmedian(x):\n",
    "                x_median = np.median(np.ravel(x))\n",
    "                return (np.abs(x-x_median)).argmin()\n",
    "            \n",
    "            self.idx_mean.append([serie, argmean(self.data[:, serie])])\n",
    "            self.idx_median.append([serie, argmedian(self.data[:, serie])])\n",
    "       \n",
    "            # Fit a gaussian distribution to get mean and std\n",
    "            self.gaussian_params_serie.append(norm.fit(self.data[:, serie]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Build an histogram for each patient\n",
    "patient_list = [];\n",
    "for pt in range(np.size(patient_sizes)):\n",
    "\n",
    "    if (pt == 0):\n",
    "        start_idx = 0\n",
    "        end_idx = patient_sizes[pt] - 1\n",
    "    else:\n",
    "        start_idx = np.sum(patient_sizes[0 : pt])\n",
    "        end_idx = np.sum(patient_sizes[0 : pt + 1]) - 1\n",
    "        \n",
    "    # Create the patient data\n",
    "    patient_list.append(Patient(data_dce[start_idx : end_idx]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## By patient analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make a by patient analysis in order to perform the normalisation. We will first start with some visualisation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition of the patient to consider"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define the patient that we want to processed\n",
    "pat_vis = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a function to build the heatmap recursively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_heatmap(patient):\n",
    "    # We need to shift the minimum value of the dataset to zero first\n",
    "    ### Find the absolute minimum and maximum over the different series\n",
    "    pt_min_intensity = min(patient.min_int_serie)\n",
    "    pt_max_intensity = max(patient.max_int_serie)\n",
    "    ### Define the maximum range of values necessary\n",
    "    range_intensities = pt_max_intensity - pt_min_intensity\n",
    "\n",
    "    # Allocate the heatmap\n",
    "    heatmap = np.zeros((len(patient.pdf_serie), int(range_intensities)))\n",
    "\n",
    "    # Build the heatmap\n",
    "    ### For each serie\n",
    "    for s in range(len(patient.pdf_serie)):\n",
    "    \n",
    "        # Define the size of the current pdf\n",
    "        arr_sz = int(patient.max_int_serie[s] - patient.min_int_serie[s])\n",
    "        # Compute the necessary offset from which the pdf has to be shifted\n",
    "        offset = int(patient.min_int_serie[s] - pt_min_intensity)\n",
    "        r = range(int(offset), arr_sz + int(offset))\n",
    "        \n",
    "        heatmap[s, range(offset, arr_sz + offset)] = patient.pdf_serie[s]\n",
    "        \n",
    "    # Return the heatmap\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to build graph from an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_graph(im, alpha):\n",
    "    from scipy.sparse import coo_matrix\n",
    "       \n",
    "    graph = np.empty((im.size, im.size), dtype=float)\n",
    "    \n",
    "    for y in np.arange(graph.shape[0]):\n",
    "        # Come back to the pixel index\n",
    "        px_idx = np.unravel_index(y, im.shape)\n",
    "        if (px_idx[0] >= (im.shape[0] - 1) or\n",
    "            px_idx[1] >= (im.shape[1] - 1)    ):\n",
    "            continue\n",
    "        # Get the pixel value \n",
    "        edge_val = im[px_idx]\n",
    "        # Assign the verteces\n",
    "        # Find the position of the verteces inside the graph\n",
    "        p_1 = np.ravel_multi_index((px_idx[0]+1, px_idx[1]), im.shape)\n",
    "        p_2 = np.ravel_multi_index((px_idx[0], px_idx[1]+1), im.shape)\n",
    "        # Assign the edge value\n",
    "        graph[y, p_1] = alpha*edge_val\n",
    "        graph[y, p_2] = (1.-alpha)*edge_val\n",
    "        \n",
    "    return coo_matrix(graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to find shortest-like path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def short_path_depend(graph, image, start, end, short_path_type):\n",
    "\n",
    "    # If we use the route_through_array from sklearn\n",
    "    if(short_path_type == 'route-through-array'):\n",
    "        from skimage.graph import route_through_array\n",
    "\n",
    "        # Call the function from skimage\n",
    "        indices, weight = route_through_array(image, start, end, geometric=True)\n",
    "        path_list = np.array(indices)\n",
    "        \n",
    "    # Or we can use the scipy shortest_path\n",
    "    elif(short_path_type == 'shortest-path'):\n",
    "        # Define a function to go from px to vertices\n",
    "        def px2v(px, im_shape):\n",
    "            return np.ravel_multi_index(px, im_shape)\n",
    "\n",
    "        # Define a function to go from vertices to px\n",
    "        def v2px(v, im_shape):\n",
    "            return np.unravel_index(v, im_shape)\n",
    "        \n",
    "        from scipy.sparse.csgraph import shortest_path\n",
    "\n",
    "        # Compute the shortest path for the whole graph\n",
    "        d, p = shortest_path(graph, return_predecessors=True)\n",
    "\n",
    "        # Find the shape of the image\n",
    "        im_sz = image.shape\n",
    "        \n",
    "        # Initiate the path\n",
    "        path_list = [end]\n",
    "\n",
    "        # Find the previous points in a loop\n",
    "        while (end != start):\n",
    "            # Convert coord from px to v\n",
    "            s_v = px2v(start, im_sz)\n",
    "            e_v = px2v(end, im_sz)\n",
    "    \n",
    "            # Find the predecessor\n",
    "            pred_v = p[s_v, e_v]\n",
    "    \n",
    "            # Convert into pixel\n",
    "            pred_px = v2px(pred_v, im_sz)\n",
    "            path_list.append(pred_px)\n",
    "    \n",
    "            # Update the last point of the path\n",
    "            end = pred_px\n",
    "    else:\n",
    "        raise ValueError('This method is not implemented!!!!')\n",
    "        \n",
    "    # Convert the list into array\n",
    "    path_list = np.array(path_list)\n",
    "        \n",
    "    # Clean the path serie by serie to have a unique value   \n",
    "    cleaned_path = []\n",
    "    for t_serie in range(np.size(image, 0)):\n",
    "        # Find all the intensities corresponding to this serie\n",
    "        poi = path_list[np.nonzero(path_list[:, 0] == t_serie)]\n",
    "    \n",
    "        # Compute the median of the second column\n",
    "        med_path = np.median(poi[:, 1])\n",
    "        cleaned_path.append([t_serie, med_path])\n",
    "\n",
    "    # Convert list to array\n",
    "    cleaned_path = np.round(np.array(cleaned_path))\n",
    "    \n",
    "    return cleaned_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fonction to shift given an estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shift_estimator(patient, estimator):\n",
    "    for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "        # Create the normalized data\n",
    "        ### Correction using the estimator\n",
    "        patient.data[:, s] = np.round(np.subtract(patient.data[:, s], (estimator[s])))\n",
    "        # Recompute the pdf\n",
    "        # Find the minimum and maximum for the given serie\n",
    "        patient.max_int_serie[s] = np.max(patient.data[:, s])\n",
    "        patient.min_int_serie[s] = np.min(patient.data[:, s])\n",
    "        # Compute the histogram\n",
    "        pdf, bin_edges = np.histogram(patient.data[:, s],\n",
    "                                      bins = int(np.round((patient.max_int_serie[s] - patient.min_int_serie[s]))), \n",
    "                                      density=True)\n",
    "        # Append the histogram\n",
    "        patient.pdf_serie[s] = pdf\n",
    "        patient.bin_edges_serie[s] = bin_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualise the data for the first time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ax = sns.heatmap(build_heatmap(patient_list[pat_vis]), cmap=\"jet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Make a test to find the shortest path with the two different methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "from skimage import img_as_float\n",
    "\n",
    "# Correct the alignment of all the patient\n",
    "for pat_vis in range(len(patient_list)):\n",
    "    \n",
    "    print 'Treating the patient #{}'.format(pat_vis)\n",
    "\n",
    "    param_alpha = .9\n",
    "    param_std = 50.\n",
    "    param_exp = 25\n",
    "\n",
    "    # Build the heatmap from the data\n",
    "    heatmap = build_heatmap(patient_list[pat_vis])\n",
    "    heatmap = gaussian_filter1d(heatmap, param_std, axis=1)\n",
    "    print 'Heatmap built'\n",
    "    # Build the conjugate map\n",
    "    #heatmap = np.exp(param_exp * heatmap)\n",
    "    image = 1. - (heatmap / np.max(heatmap))\n",
    "    # Compute the exponential map to increase highly the difference\n",
    "    image = img_as_float(np.exp(param_exp * image))\n",
    "    #image = np.log10(1. + param_exp * image)\n",
    "    print 'Image built'\n",
    "\n",
    "    # Build the graph from the image\n",
    "    graph = build_graph(image, param_alpha)\n",
    "    print 'Graph built'\n",
    "\n",
    "    # Compute the shortest path\n",
    "    ### Find the starting and ending point of the map\n",
    "    def median_serie(patient, serie):\n",
    "        return np.median(patient.data[:, serie], axis=0)\n",
    "\n",
    "    ### Find the offset\n",
    "    offset = int(np.min(patient_list[pat_vis].min_int_serie))\n",
    "\n",
    "    start = (0, \n",
    "             int(np.ravel(median_serie(patient_list[pat_vis], 0))[0] - offset))\n",
    "    end = (np.size(heatmap, 0) - 1, \n",
    "           int(np.ravel(median_serie(patient_list[pat_vis], np.size(heatmap, 0) - 1))[0] - offset))\n",
    "    print 'Starting and ending point computed: {} - {}'.format(start, end)\n",
    "\n",
    "    # Call the algorithm to fing the shortest path\n",
    "    path_idx = short_path_depend(graph, image, start, end, 'shortest-path')\n",
    "\n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(image, cmap=\"jet\")\n",
    "    sns.plt.scatter(path_idx[:, 1], 39 - path_idx[:, 0], label='mean', c='green', alpha=0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Remove the offset to the data\n",
    "    path_idx[:, 1] += offset\n",
    "\n",
    "    shift_estimator(patient_list[pat_vis], path_idx[:, 1])\n",
    "\n",
    "    # Build the heatmap from the data\n",
    "    heatmap = build_heatmap(patient_list[pat_vis])\n",
    "    heatmap = gaussian_filter1d(heatmap, param_std, axis=1)\n",
    "    print 'Heatmap built'\n",
    "    # Build the conjugate map\n",
    "    #heatmap = np.exp(param_exp * heatmap)\n",
    "    image = 1. - (heatmap / np.max(heatmap))\n",
    "    # Compute the exponential map to increase highly the difference\n",
    "    image = img_as_float(np.exp(param_exp * image))\n",
    "    print 'Image built'\n",
    "\n",
    "    # Build the graph from the image\n",
    "    graph = build_graph(image, param_alpha)\n",
    "    print 'Graph built'\n",
    "\n",
    "    # Compute the shortest path\n",
    "    ### Find the offset\n",
    "    offset = int(np.min(patient_list[pat_vis].min_int_serie))\n",
    "\n",
    "    start = (0, -offset)\n",
    "    end = (np.size(heatmap, 0) - 1, -offset)\n",
    "    print 'Starting and ending point computed: {} - {}'.format(start, end)\n",
    "\n",
    "    # Call the algorithm to fing the shortest path\n",
    "    path_idx = short_path_depend(graph, image, start, end, 'route-through-array')\n",
    "\n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(image, cmap=\"jet\")\n",
    "    sns.plt.scatter(path_idx[:, 1], 39 - path_idx[:, 0], label='mean', c='green', alpha=0.9)\n",
    "    plt.show()\n",
    "\n",
    "    # Remove the offset to the data\n",
    "    path_idx[:, 1] += offset\n",
    "\n",
    "    shift_estimator(patient_list[pat_vis], path_idx[:, 1])\n",
    "\n",
    "    # Plot the final results\n",
    "    plt.figure()\n",
    "    ax = sns.heatmap(build_heatmap(patient_list[pat_vis]), cmap=\"jet\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute the Mean Squared Estimator (MSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "estim = []\n",
    "vari = []\n",
    "# Go in each serie of the DCE\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    # s is the pdf and we want to estmiate the variance considering 0 as the true mean\n",
    "    # We will compute: sum ip_i ** 2\n",
    "    ### We have to create the i - find the middle of the bin and the right number of value\n",
    "    i_arr = (patient_list[pat_vis].bin_edges_serie[s][:-1] + \n",
    "             patient_list[pat_vis].bin_edges_serie[s][1:]    ) / 2.\n",
    "    ### Compute the variance\n",
    "    ipi_arr = (i_arr ** 2) * patient_list[pat_vis].pdf_serie[s]\n",
    "    \n",
    "    ### The estimator correspond to the sum normalise by the number of bins\n",
    "    estim.append(np.sum(ipi_arr))# / float(len(i_arr)))\n",
    "    vari.append(np.var(patient_list[pat_vis].data[:, s]))\n",
    "    \n",
    "    \n",
    "plt.plot(estim, label='our estimate')\n",
    "plt.plot(vari, label='variance')\n",
    "plt.legend()\n",
    "\n",
    "# Save the estimator\n",
    "patient_list[pat_vis].mse_est = estim\n",
    "patient_list[pat_vis].mse_var = vari    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let it on the side"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import img_as_float\n",
    "\n",
    "param_alpha = .99\n",
    "param_std = 3\n",
    "param_exp = 20\n",
    "\n",
    "# Build the heatmap from the data\n",
    "heatmap = build_heatmap(patient_list[pat_vis])\n",
    "print 'Heatmap built'\n",
    "# Build the conjugate map\n",
    "image = 1. - (heatmap / np.max(heatmap))\n",
    "# Use a gaussian filter per row\n",
    "# image = gaussian_filter1d(image, param_std, 0)\n",
    "# Compute the exponential map to increase highly the difference\n",
    "image = np.log10((1. + param_exp * image))\n",
    "print 'Image built'\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.heatmap(image, cmap=\"jet\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the index of the patient to visualise\n",
    "pat_vis = 1\n",
    "\n",
    "pat_heatmap = []\n",
    "#for pat_vis in range(len(patient_list)):\n",
    "\n",
    "# Allocate the heatmap\n",
    "### Find the maximum and minimum from all series\n",
    "pt_min_intensity = min(patient_list[pat_vis].min_int_serie)\n",
    "pt_max_intensity = max(patient_list[pat_vis].max_int_serie)\n",
    "### Allocate the heat map with the right indexing\n",
    "heatmap_z_raw = np.zeros((len(patient_list[pat_vis].pdf_serie),\n",
    "                                      int(pt_max_intensity)));\n",
    "\n",
    "heatmap_y = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    str_pt = 'Serie ' + str(s) + ' '\n",
    "    heatmap_y.append(str_pt)\n",
    "    heatmap_z_raw[s, range(int(patient_list[pat_vis].min_int_serie[s]),\n",
    "                           int(patient_list[pat_vis].max_int_serie[s]))] = patient_list[pat_vis].pdf_serie[s]\n",
    "\n",
    "stat_median = np.ravel(patient_list[pat_vis].median_data_serie).astype(int)\n",
    "stat_mean = np.ravel(patient_list[pat_vis].mean_data_serie).astype(int)\n",
    "    \n",
    "ax = sns.heatmap(heatmap_z_raw, cmap=\"jet\")\n",
    "sns.plt.scatter(np.ravel(patient_list[pat_vis].median_data_serie), np.arange(39, -1, -1), label='mean', c='green', alpha=0.9)\n",
    "sns.plt.scatter(np.ravel(patient_list[pat_vis].mean_data_serie), np.arange(39, -1, -1), label='median', c='red', alpha=0.9)\n",
    "#sns.plt.scatter(np.ravel(patient_list[pat_vis].mode_data_serie), np.arange(39, -1, -1), label='median', c='blue', alpha=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "from skimage import img_as_ubyte\n",
    "\n",
    "# Define the starting and ending seeds\n",
    "start = [0, stat_median[0]]\n",
    "end = [39, stat_median[-1]]\n",
    "\n",
    "# Compute the inverse image\n",
    "\n",
    "from skimage.filters import gaussian_filter\n",
    "\n",
    "image = 1. - (heatmap_z_raw / np.max(heatmap_z_raw))\n",
    "\n",
    "from scipy.ndimage.filters import gaussian_filter1d\n",
    "std_gauss = 50\n",
    "\n",
    "im2 = []\n",
    "for r in image:\n",
    "    im2.append(gaussian_filter1d(r, std_gauss))\n",
    "im2 = np.array(im2)\n",
    "#image = im2\n",
    "\n",
    "#for c in image.T:\n",
    "#    c = gaussian_filter1d(c, std_gauss)\n",
    "    \n",
    "image = np.exp(15*image)\n",
    "\n",
    "# Adaptive Equalization\n",
    "# Contrast stretching\n",
    "#p2, p98 = np.percentile(image, (2, 98))\n",
    "#image = exposure.rescale_intensity(image, in_range=(p2, p98))\n",
    "#image = np.log(exposure.equalize_hist(image))\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.heatmap(image, cmap=\"jet\")\n",
    "\n",
    "# Find the shortest path\n",
    "start = [0, stat_median[0]]\n",
    "end = [39, stat_median[-1]]\n",
    "\n",
    "start = [0, 235]\n",
    "end = [39, 240]\n",
    "\n",
    "\n",
    "\n",
    "sns.plt.scatter(indices[1], np.abs(indices[0]-39), label='mean', c='blue', alpha=0.9)\n",
    "\n",
    "#plot_data = Data([Heatmap(z=heatmap_z_raw, y=heatmap_y, colorscale='Jet')])\n",
    "#layout = Layout(margin=Margin(l=0, r=0, b=0, t=0))\n",
    "#plot_data = Data(pat_heatmap)\n",
    "# Define a figure\n",
    "#fig = Figure(data=plot_data)\n",
    "#py.iplot(fig, filename='heatmap-dce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "graph = build_graph(image)\n",
    "\n",
    "graph = coo_matrix(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.heatmap(heatmap_z_raw, cmap=\"jet\")\n",
    "path_list = np.array(path_list)\n",
    "sns.plt.scatter(path_list[:, 1], 39 - path_list[:, 0], label='mean', c='red', alpha=0.9)\n",
    "sns.plt.scatter(np.ravel(patient_list[pat_vis].median_data_serie), np.arange(39, -1, -1), label='mean', c='green', alpha=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clean the path by taking the median for each row of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure()\n",
    "ax = sns.heatmap(heatmap_z_raw, cmap=\"jet\")\n",
    "path_list = np.array(path_list)\n",
    "sns.plt.scatter(cleaned_path[:, 1], 39 - cleaned_path[:, 0], label='mean', c='red', alpha=0.9)\n",
    "sns.plt.scatter(np.ravel(patient_list[pat_vis].median_data_serie), np.arange(39, -1, -1), label='mean', c='green', alpha=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define the index of the patient to visualise\n",
    "pat_vis = 1\n",
    "\n",
    "pat_heatmap = []\n",
    "#for pat_vis in range(len(patient_list)):\n",
    "\n",
    "# Allocate the heatmap\n",
    "### Find the maximum and minimum from all series\n",
    "pt_min_intensity = min(patient_list[pat_vis].min_int_serie)\n",
    "pt_max_intensity = max(patient_list[pat_vis].max_int_serie)\n",
    "### Allocate the heat map with the right indexing\n",
    "heatmap_z_raw = np.zeros((len(patient_list[pat_vis].pdf_serie),\n",
    "                                      int(pt_max_intensity)));\n",
    "\n",
    "heatmap_y = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    str_pt = 'Serie ' + str(s) + ' '\n",
    "    heatmap_y.append(str_pt)\n",
    "    heatmap_z_raw[s, range(int(patient_list[pat_vis].min_int_serie[s]),\n",
    "                           int(patient_list[pat_vis].max_int_serie[s]))] = patient_list[pat_vis].pdf_serie[s]\n",
    "        \n",
    "plot_data = Data([Heatmap(z=heatmap_z_raw, y=heatmap_y, colorscale='Jet')])\n",
    "#layout = Layout(margin=Margin(l=0, r=0, b=0, t=0))\n",
    "#plot_data = Data(pat_heatmap)\n",
    "# Define a figure\n",
    "fig = Figure(data=plot_data)\n",
    "py.iplot(fig, filename='heatmap-dce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "serie_pdf = []\n",
    "for ind, serie in enumerate(patient_list[pat_vis].pdf_serie):\n",
    "    serie_pdf.append(np.squeeze(np.asarray(heatmap_z_raw[ind,:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction using only the mean, median, or graph path estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    # Create the normalized data\n",
    "    ### Correction using the median\n",
    "    #patient_list[pat_vis].data[:, s] = np.round(patient_list[pat_vis].data[:, s] - (patient_list[pat_vis].median_data_serie[s]))\n",
    "    patient_list[pat_vis].data[:, s] = np.round(np.subtract(patient_list[pat_vis].data[:, s], (patient_list[pat_vis].graph_path[s])))\n",
    "    # Recompute the pdf\n",
    "    # Find the minimum and maximum for the given serie\n",
    "    patient_list[pat_vis].max_int_serie[s] = np.max(patient_list[pat_vis].data[:, s])\n",
    "    patient_list[pat_vis].min_int_serie[s] = np.min(patient_list[pat_vis].data[:, s])\n",
    "    # Compute the histogram\n",
    "    pdf, bin_edges = np.histogram(patient_list[pat_vis].data[:, s],\n",
    "                                  bins = int(np.round((patient_list[pat_vis].max_int_serie[s] - patient_list[pat_vis].min_int_serie[s]))), \n",
    "                                  density=True)\n",
    "    # Append the histogram\n",
    "    patient_list[pat_vis].pdf_serie[s] = pdf\n",
    "    patient_list[pat_vis].bin_edges_serie[s] = bin_edges\n",
    "    \n",
    "    #plt.figure()\n",
    "    #width = 0.7 * (bin_edges[1] - bin_edges[0])\n",
    "    #center = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "    #plt.bar(center, pdf, align='center', width=width)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can show the data with mean, median, or graph path estimator shifted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pat_heatmap = []\n",
    "#for pat_vis in range(len(patient_list)):\n",
    "\n",
    "# Allocate the heatmap\n",
    "### Find the maximum and minimum from all series\n",
    "pt_min_intensity = np.abs(min(patient_list[pat_vis].min_int_serie))\n",
    "pt_max_intensity = np.abs(min(patient_list[pat_vis].min_int_serie)) + max(patient_list[pat_vis].max_int_serie)\n",
    "### Allocate the heat map with the right indexing\n",
    "heatmap_z_raw = np.zeros((len(patient_list[pat_vis].pdf_serie), int(pt_max_intensity)))\n",
    "\n",
    "heatmap_y = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    str_pt = 'Serie ' + str(s) + ' '\n",
    "    heatmap_y.append(str_pt)\n",
    "    \n",
    "    arr_sz = int(np.abs(patient_list[pat_vis].min_int_serie[s]) + patient_list[pat_vis].max_int_serie[s])\n",
    "    offset = pt_min_intensity - np.abs(patient_list[pat_vis].min_int_serie[s])\n",
    "    print pt_min_intensity\n",
    "    r = range(int(offset), arr_sz+int(offset))\n",
    "        \n",
    "    heatmap_z_raw[s, r] = patient_list[pat_vis].pdf_serie[s]\n",
    "        \n",
    "plot_data = Data([Heatmap(z=heatmap_z_raw, y=heatmap_y, colorscale='Jet')])\n",
    "#layout = Layout(margin=Margin(l=0, r=0, b=0, t=0))\n",
    "#plot_data = Data(pat_heatmap)\n",
    "# Define a figure\n",
    "fig = Figure(data=plot_data)\n",
    "py.iplot(fig, filename='heatmap-dce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can plot the variation of the std over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(patient_list[pat_vis].std_data_serie, 'o-')\n",
    "plt.xlabel('Serie')\n",
    "plt.ylabel('Standard deviation variations')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not useful for the moment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single patient we will start to fit a rician distrubution for each dce serie."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the function to fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "\n",
    "# For the Rician\n",
    "def myRice(x, factor, v, shift, std):\n",
    "    return rice.pdf(x, v, shift, std) / factor\n",
    "\n",
    "# Define the parameters for the Rician\n",
    "riceParameters = namedtuple('riceParameters',\n",
    "                            ['factor', 'v', 'shift', 'std'])\n",
    "\n",
    "# For the Gaussian\n",
    "def myGaussian(x, factor, mean, std):\n",
    "    return norm.pdf(x, mean, std) / factor\n",
    "\n",
    "# Define the parameters for the Gaussian\n",
    "gaussianParameters = namedtuple('gaussianParameters',\n",
    "                                ['factor', 'mean', 'std'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fit the distribution of one patient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "db_max_intensity = max(patient_list[pat_vis].max_int_serie)\n",
    "db_min_intensity = min(patient_list[pat_vis].min_int_serie)\n",
    "\n",
    "# Get the initial guess for the rician distribution\n",
    "def get_rice_initial_parameters(patient, pdf, serie):\n",
    "    \n",
    "    # Get the mean from the patient information\n",
    "    v = patient.mean_data_serie[serie] / db_max_intensity\n",
    "    std = patient.std_data_serie[serie] / db_max_intensity\n",
    "    factor = db_max_intensity\n",
    "    \n",
    "    # Compute the cumulative sum of the pdf\n",
    "    cdf = np.cumsum(pdf)\n",
    "    loc = float(np.argmax(cdf > .01)) / db_max_intensity\n",
    "    #loc = np.argmax(cdf > .01)/db_max_intensity\n",
    "    \n",
    "    return riceParameters(factor, v, loc, std)\n",
    "\n",
    "# For each serie get the initial parameter\n",
    "rice_init = [get_rice_initial_parameters(patient_list[pat_vis], pdf, s) for s, pdf in enumerate(serie_pdf)]\n",
    "rice_fitted_param = []\n",
    "rice_fiting_error = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    popt, pcov = curve_fit(myRice,\n",
    "                           np.linspace(0, 1., len(np.squeeze(np.asarray(heatmap_z_raw[s, :])))),\n",
    "                           np.squeeze(np.asarray(heatmap_z_raw[s, :])),\n",
    "                           p0=(rice_init[s].factor, rice_init[s].v,\n",
    "                               rice_init[s].shift, rice_init[s].std),\n",
    "                           maxfev=10000)\n",
    "    rice_fitted_param.append(riceParameters(popt[0], popt[1], popt[2], popt[3],))\n",
    "    rice_fiting_error.append(pcov)\n",
    "    \n",
    "# Get the initial guess for the rician distribution\n",
    "def get_gaussian_initial_parameters(patient, pdf, serie):\n",
    "    \n",
    "    # Get the mean from the patient information\n",
    "    mean = patient.mean_data_serie[serie] / db_max_intensity\n",
    "    std = patient.std_data_serie[serie] / db_max_intensity\n",
    "    factor = db_max_intensity\n",
    "        \n",
    "    return gaussianParameters(factor, mean, std)\n",
    "\n",
    "# For each serie get the initial parameter\n",
    "gaussian_init = [get_gaussian_initial_parameters(patient_list[pat_vis], pdf, s) for s, pdf in enumerate(serie_pdf)]\n",
    "gaussian_fitted_param = []\n",
    "gaussian_fiting_error = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    popt, pcov = curve_fit(myGaussian,\n",
    "                           np.linspace(0, 1., len(np.squeeze(np.asarray(heatmap_z_raw[s, :])))),\n",
    "                           np.squeeze(np.asarray(heatmap_z_raw[s, :])),\n",
    "                           p0=(gaussian_init[s].factor, gaussian_init[s].mean, gaussian_init[s].std),\n",
    "                           maxfev=10000)\n",
    "    gaussian_fitted_param.append(gaussianParameters(popt[0], popt[1], popt[2],))\n",
    "    gaussian_fiting_error.append(pcov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def output_msg(init, fitted):\n",
    "    output_line = \"{0:24s} ---> {1}:{2}\\n\"\n",
    "    msg = \"\\n    initialization \\t\\t fitted\\n\"\n",
    "    for param_name in riceParameters._fields:\n",
    "        msg = msg+(output_line.format(\n",
    "            param_name+': '+eval('\"{0}\".format(init.'+'{0:s}'.format(param_name)+')'),\n",
    "            param_name,\n",
    "            eval('\"{0}\".format(fitted.'+'{0:s}'.format(param_name)+')')))\n",
    "    return msg\n",
    "\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "       \n",
    "    plt.figure()\n",
    "    x = np.linspace(0, 1., int(db_max_intensity))\n",
    "    plt.plot(x, np.squeeze(np.asarray(heatmap_z_raw[s, :])), label='data')\n",
    "    \n",
    "    plt.plot(x, myRice(x,\n",
    "                       rice_fitted_param[s].factor,\n",
    "                       rice_fitted_param[s].v,\n",
    "                       rice_fitted_param[s].shift,\n",
    "                       rice_fitted_param[s].std), label='rician')\n",
    "    plt.plot(x, myGaussian(x,\n",
    "                           gaussian_fitted_param[s].factor,\n",
    "                           gaussian_fitted_param[s].mean,\n",
    "                           gaussian_fitted_param[s].std), label='gaussian')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### Estimation of the mean for each PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    if np.isnan(rice.mean(rice_fitted_param[s].v,\n",
    "                       rice_fitted_param[s].shift,\n",
    "                       rice_fitted_param[s].std)):\n",
    "        print 'Mean using Gaussian estimation: {}'.format(norm.mean(gaussian_fitted_param[s].mean,\n",
    "                                                                    gaussian_fitted_param[s].std))\n",
    "    else:\n",
    "        print 'Mean using Rician estimatation: {}'.format(rice.mean(rice_fitted_param[s].v,\n",
    "                                                                    rice_fitted_param[s].shift,\n",
    "                                                                    rice_fitted_param[s].std))\n",
    "        print 'Mean using Gaussian estimation: {}'.format(norm.mean(gaussian_fitted_param[s].mean,\n",
    "                                                                    gaussian_fitted_param[s].std))\n",
    "    print ''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correct the mean offset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    # Estimate the mean as previously presented\n",
    "    if np.isnan(rice.mean(rice_fitted_param[s].v,\n",
    "                       rice_fitted_param[s].shift,\n",
    "                       rice_fitted_param[s].std)):\n",
    "        mean_corr = norm.mean(gaussian_fitted_param[s].mean,\n",
    "                      gaussian_fitted_param[s].std)\n",
    "    else:\n",
    "        mean_corr = rice.mean(rice_fitted_param[s].v,\n",
    "                              rice_fitted_param[s].shift,\n",
    "                              rice_fitted_param[s].std)\n",
    "    # Make the correction\n",
    "    patient_list[pat_vis].data[:, s] = np.round(patient_list[pat_vis].data[:, s] - (mean_corr * db_max_intensity))\n",
    "    # Recompute the pdf\n",
    "    # Find the minimum and maximum for the given serie\n",
    "    patient_list[pat_vis].max_int_serie[s] = np.max(patient_list[pat_vis].data[:, s])\n",
    "    patient_list[pat_vis].min_int_serie[s] = np.min(patient_list[pat_vis].data[:, s])\n",
    "    # Compute the histogram\n",
    "    pdf, bin_edges = np.histogram(patient_list[pat_vis].data[:, s],\n",
    "                                  bins = int(np.round((patient_list[pat_vis].max_int_serie[s] - patient_list[pat_vis].min_int_serie[s]))), \n",
    "                                  density=True)\n",
    "    # Append the histogram\n",
    "    patient_list[pat_vis].pdf_serie[s] = pdf\n",
    "    patient_list[pat_vis].bin_edges_serie[s] = bin_edges"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Recompute the heatmap to see the improvement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pat_heatmap = []\n",
    "#for pat_vis in range(len(patient_list)):\n",
    "\n",
    "# Allocate the heatmap\n",
    "### Find the maximum and minimum from all series\n",
    "pt_min_intensity = np.abs(min(patient_list[pat_vis].min_int_serie))\n",
    "pt_max_intensity = np.abs(min(patient_list[pat_vis].min_int_serie)) + max(patient_list[pat_vis].max_int_serie)\n",
    "### Allocate the heat map with the right indexing\n",
    "heatmap_z_raw = np.zeros((len(patient_list[pat_vis].pdf_serie), int(pt_max_intensity)))\n",
    "\n",
    "heatmap_y = []\n",
    "for s in range(len(patient_list[pat_vis].pdf_serie)):\n",
    "    str_pt = 'Serie ' + str(s) + ' '\n",
    "    heatmap_y.append(str_pt)\n",
    "    \n",
    "    arr_sz = int(np.abs(patient_list[pat_vis].min_int_serie[s]) + patient_list[pat_vis].max_int_serie[s])\n",
    "    offset = pt_min_intensity - np.abs(patient_list[pat_vis].min_int_serie[s])\n",
    "    r = range(int(offset), arr_sz+int(offset))\n",
    "        \n",
    "    heatmap_z_raw[s, r] = patient_list[pat_vis].pdf_serie[s]\n",
    "        \n",
    "plot_data = Data([Heatmap(z=heatmap_z_raw, y=heatmap_y, colorscale='Jet')])\n",
    "#layout = Layout(margin=Margin(l=0, r=0, b=0, t=0))\n",
    "#plot_data = Data(pat_heatmap)\n",
    "# Define a figure\n",
    "fig = Figure(data=plot_data)\n",
    "py.iplot(fig, filename='heatmap-dce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part to work with gradient descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
